{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = pd.read_csv('train_bigger.csv', dtype={\"from_2\": object, \"type\": object, \"category\": object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_type</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>text</th>\n",
       "      <th>from_2</th>\n",
       "      <th>type</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personal_chat</td>\n",
       "      <td>TZ155 Nontobeko Mthembu</td>\n",
       "      <td>226915</td>\n",
       "      <td>2018-03-22T17:59:29</td>\n",
       "      <td>Setup (Master)</td>\n",
       "      <td>Sawubona Jessie üòä. ;;We can see that you are e...</td>\n",
       "      <td>setup</td>\n",
       "      <td>noncontent</td>\n",
       "      <td>setup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>private_group</td>\n",
       "      <td>19:00 (10/07) Thabiso (2)üèÜ3Ô∏è‚É£</td>\n",
       "      <td>376217</td>\n",
       "      <td>2018-04-03T19:01:47</td>\n",
       "      <td>ThishaBot</td>\n",
       "      <td>Any questions?</td>\n",
       "      <td>bot</td>\n",
       "      <td>noncontent</td>\n",
       "      <td>conv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>private_group</td>\n",
       "      <td>20:00 (11/07) Irfaan (2)üèÜ3Ô∏è‚É£</td>\n",
       "      <td>873757</td>\n",
       "      <td>2018-05-15T20:52:52</td>\n",
       "      <td>Irfaan Moolla</td>\n",
       "      <td>Today</td>\n",
       "      <td>student</td>\n",
       "      <td>noncontent</td>\n",
       "      <td>conv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>private_group</td>\n",
       "      <td>13:00 (10/07) Fatima (3)üèÜ3Ô∏è‚É£</td>\n",
       "      <td>1368973</td>\n",
       "      <td>2018-07-02T19:05:13</td>\n",
       "      <td>TZ Simphiwe Mfaba</td>\n",
       "      <td>Kulungile üí™</td>\n",
       "      <td>tutor</td>\n",
       "      <td>noncontent</td>\n",
       "      <td>conv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>private_group</td>\n",
       "      <td>20:00 (09/07) Jenna (1)üèÜ4‚É£</td>\n",
       "      <td>1234119</td>\n",
       "      <td>2018-06-18T20:12:31</td>\n",
       "      <td>ThishaBot</td>\n",
       "      <td>Surprisingly, the patient seems satisfied with...</td>\n",
       "      <td>bot</td>\n",
       "      <td>content</td>\n",
       "      <td>non mcq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    channel_type                   channel_name       id                 date  \\\n",
       "0  personal_chat        TZ155 Nontobeko Mthembu   226915  2018-03-22T17:59:29   \n",
       "1  private_group  19:00 (10/07) Thabiso (2)üèÜ3Ô∏è‚É£   376217  2018-04-03T19:01:47   \n",
       "2  private_group   20:00 (11/07) Irfaan (2)üèÜ3Ô∏è‚É£   873757  2018-05-15T20:52:52   \n",
       "3  private_group   13:00 (10/07) Fatima (3)üèÜ3Ô∏è‚É£  1368973  2018-07-02T19:05:13   \n",
       "4  private_group     20:00 (09/07) Jenna (1)üèÜ4‚É£  1234119  2018-06-18T20:12:31   \n",
       "\n",
       "                from                                               text  \\\n",
       "0     Setup (Master)  Sawubona Jessie üòä. ;;We can see that you are e...   \n",
       "1          ThishaBot                                     Any questions?   \n",
       "2      Irfaan Moolla                                              Today   \n",
       "3  TZ Simphiwe Mfaba                                        Kulungile üí™   \n",
       "4          ThishaBot  Surprisingly, the patient seems satisfied with...   \n",
       "\n",
       "    from_2        type category  \n",
       "0    setup  noncontent    setup  \n",
       "1      bot  noncontent     conv  \n",
       "2  student  noncontent     conv  \n",
       "3    tutor  noncontent     conv  \n",
       "4      bot     content  non mcq  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled.dropna(subset=['category'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled = pd.read_csv('labeled_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled.drop(columns=['text_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = labeled['text'].values.tolist()\n",
    "val_texts = unlabeled['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing import text\n",
    "\n",
    "TOP_K = 20000\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "def sequence_vectorize(train_texts, val_texts):\n",
    "    \"\"\"Vectorizes texts as sequence vectors.\n",
    "\n",
    "    1 text = 1 sequence vector with fixed length.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val, word_index: vectorized training and validation\n",
    "            texts and word index dictionary.\n",
    "    \"\"\"\n",
    "    # Create vocabulary with training texts.\n",
    "    tokenizer = text.Tokenizer(num_words=TOP_K)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "    # Vectorize training and validation texts.\n",
    "    x_train = tokenizer.texts_to_sequences(train_texts)\n",
    "    x_val = tokenizer.texts_to_sequences(val_texts)\n",
    "\n",
    "    # Get max sequence length.\n",
    "    max_length = len(max(x_train, key=len))\n",
    "    if max_length > MAX_SEQUENCE_LENGTH:\n",
    "        max_length = MAX_SEQUENCE_LENGTH\n",
    "\n",
    "    # Fix sequence length to max value. Sequences shorter than the length are\n",
    "    # padded in the beginning and sequences longer are truncated\n",
    "    # at the beginning.\n",
    "    x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
    "    x_val = sequence.pad_sequences(x_val, maxlen=max_length)\n",
    "    return x_train, x_val, tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
