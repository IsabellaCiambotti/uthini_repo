{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>format as test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_bigger.csv', dtype={\"from_2\": object, \"type\": object, \"category\": object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset=['category'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('labeled_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['text_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['category']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['text']\n",
    "y = train['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state = 2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> label encode and one-hot encode categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "y_train=le.fit_transform(y_train)\n",
    "y_test=le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=6\n",
    "y_train = keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> use sklearn's vectorizer to format text data at word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483, 673)\n",
      "(121, 673)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_vec = TfidfVectorizer(analyzer='word',\n",
    "                         min_df=2,\n",
    "                         strip_accents='unicode',\n",
    "                         token_pattern=r'\\w{1,}',\n",
    "                         ngram_range=(2,3)\n",
    "                         )\n",
    "x_train_vec = tf_vec.fit_transform(x_train)\n",
    "x_test_vec = tf_vec.transform(x_test)\n",
    "print (x_train_vec.shape)\n",
    "print (x_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores- from kaggle:https://www.kaggle.com/ksjpswaroop/parameter-tuning-rf-randomized-search\n",
    "def report(results, n_top=5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import RandomizedSearchCV as RS\n",
    "from scipy import stats\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def create_model_2(dropout_rate=0.0, weight_constraint=0, hidden_layers=1, neurons=1):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(neurons, activation='relu', input_shape=(673,)))\n",
    "    for i in np.arange(hidden_layers):\n",
    "        model2.add(Dense(neurons, activation='relu'))\n",
    "        model2.add(Dropout(dropout_rate))\n",
    "    model2.add(Dense(6, activation='softmax'))\n",
    "    model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KerasClassifier(build_fn=create_model_2, verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'neurons': stats.randint(2, 52),\n",
    "         'hidden_layers': stats.randint(1, 5),\n",
    "         'dropout_rate': stats.uniform(0.0, 0.9),\n",
    "         'weight_constraint': stats.uniform(1, 5)\n",
    "         }\n",
    "n_iter = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand2 = RS(estimator=model2, param_distributions=params, n_jobs=-1, cv=4, n_iter=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_search2 = rand2.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.547 (std: 0.069)\n",
      "Parameters: {'dropout_rate': 0.17448185249263476, 'hidden_layers': 1, 'neurons': 47, 'weight_constraint': 4.91121310218517}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.536 (std: 0.072)\n",
      "Parameters: {'dropout_rate': 0.3721020759554231, 'hidden_layers': 2, 'neurons': 19, 'weight_constraint': 5.643586364015265}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.522 (std: 0.084)\n",
      "Parameters: {'dropout_rate': 0.24349017520726524, 'hidden_layers': 1, 'neurons': 33, 'weight_constraint': 2.928270933187144}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.520 (std: 0.068)\n",
      "Parameters: {'dropout_rate': 0.08400763927433745, 'hidden_layers': 2, 'neurons': 27, 'weight_constraint': 4.428423941867987}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.520 (std: 0.078)\n",
      "Parameters: {'dropout_rate': 0.24344114994887692, 'hidden_layers': 1, 'neurons': 50, 'weight_constraint': 1.8740943874140523}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(rand_search2.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "batch_size= [4,8,16,32,64,128,256]\n",
    "epochs=[4,8,16,32,64,128]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_pred = grid.fit(x_train_vec, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(grid_pred.best_score_)\n",
    "print(grid_pred.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(x=x_train_vec, y=y_train, batch_size=?, epochs=?)\n",
    "#test_loss, test_acc = model.evaluate(x_test_vec, y_test)\n",
    "#test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_model_2(optimizer='Adam'):\n",
    "    inputs = layers.Input(shape=(2163,))\n",
    "    hidden_1 = layers.Dense(units=32, activation='relu')(inputs)\n",
    "    dropout1 = layers.Dropout(0.5)(hidden_1)\n",
    "    hidden_2 = layers.Dense(units=32, activation='relu')(hidden_1)\n",
    "    dropout_2 = layers.Dropout(0.5)(hidden_2)\n",
    "    hidden_3 = layers.Dense(units=32, activation='relu')(hidden_2)\n",
    "    dropout_3 = layers.Dropout(0.5)(hidden_3)\n",
    "    hidden_4 = layers.Dense(units=32, activation='relu')(hidden_3)\n",
    "    dropout_4 = layers.Dropout(0.5)(hidden_3)\n",
    "    hidden_5 = layers.Dense(units=32, activation='relu')(hidden_4)\n",
    "    dropout_5 = layers.Dropout(0.5)(hidden_4)\n",
    "    outputs = layers.Dense(6, activation='softmax')(hidden_5)\n",
    "\n",
    "    model2= models.Model(inputs=inputs, outputs=outputs)\n",
    "    #model.summary()\n",
    "    model2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model_2, verbose=0, batch_size=32, epochs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_pred = grid.fit(x_train_vec, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(grid_pred.best_score_)\n",
    "print(grid_pred.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
