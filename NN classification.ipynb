{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>format as test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_bigger.csv', dtype={\"from_2\": object, \"type\": object, \"category\": object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset=['category'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('labeled_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['text_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['category']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_2']=train['from_2'].astype(str) + \" \" + train['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_type</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>text</th>\n",
       "      <th>from_2</th>\n",
       "      <th>type</th>\n",
       "      <th>category</th>\n",
       "      <th>text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personal_chat</td>\n",
       "      <td>TZ155 Nontobeko Mthembu</td>\n",
       "      <td>226915</td>\n",
       "      <td>2018-03-22T17:59:29</td>\n",
       "      <td>Setup (Master)</td>\n",
       "      <td>Sawubona Jessie üòä. ;;We can see that you are e...</td>\n",
       "      <td>setup</td>\n",
       "      <td>noncontent</td>\n",
       "      <td>setup</td>\n",
       "      <td>setup Sawubona Jessie üòä. ;;We can see that you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>private_group</td>\n",
       "      <td>19:00 (10/07) Thabiso (2)üèÜ3Ô∏è‚É£</td>\n",
       "      <td>376217</td>\n",
       "      <td>2018-04-03T19:01:47</td>\n",
       "      <td>ThishaBot</td>\n",
       "      <td>Any questions?</td>\n",
       "      <td>bot</td>\n",
       "      <td>noncontent</td>\n",
       "      <td>conv</td>\n",
       "      <td>bot Any questions?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>private_group</td>\n",
       "      <td>20:00 (11/07) Irfaan (2)üèÜ3Ô∏è‚É£</td>\n",
       "      <td>873757</td>\n",
       "      <td>2018-05-15T20:52:52</td>\n",
       "      <td>Irfaan Moolla</td>\n",
       "      <td>Today</td>\n",
       "      <td>student</td>\n",
       "      <td>noncontent</td>\n",
       "      <td>conv</td>\n",
       "      <td>student Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>private_group</td>\n",
       "      <td>13:00 (10/07) Fatima (3)üèÜ3Ô∏è‚É£</td>\n",
       "      <td>1368973</td>\n",
       "      <td>2018-07-02T19:05:13</td>\n",
       "      <td>TZ Simphiwe Mfaba</td>\n",
       "      <td>Kulungile üí™</td>\n",
       "      <td>tutor</td>\n",
       "      <td>noncontent</td>\n",
       "      <td>conv</td>\n",
       "      <td>tutor Kulungile üí™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>private_group</td>\n",
       "      <td>20:00 (09/07) Jenna (1)üèÜ4‚É£</td>\n",
       "      <td>1234119</td>\n",
       "      <td>2018-06-18T20:12:31</td>\n",
       "      <td>ThishaBot</td>\n",
       "      <td>Surprisingly, the patient seems satisfied with...</td>\n",
       "      <td>bot</td>\n",
       "      <td>content</td>\n",
       "      <td>non mcq</td>\n",
       "      <td>bot Surprisingly, the patient seems satisfied ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    channel_type                   channel_name       id                 date  \\\n",
       "0  personal_chat        TZ155 Nontobeko Mthembu   226915  2018-03-22T17:59:29   \n",
       "1  private_group  19:00 (10/07) Thabiso (2)üèÜ3Ô∏è‚É£   376217  2018-04-03T19:01:47   \n",
       "2  private_group   20:00 (11/07) Irfaan (2)üèÜ3Ô∏è‚É£   873757  2018-05-15T20:52:52   \n",
       "3  private_group   13:00 (10/07) Fatima (3)üèÜ3Ô∏è‚É£  1368973  2018-07-02T19:05:13   \n",
       "4  private_group     20:00 (09/07) Jenna (1)üèÜ4‚É£  1234119  2018-06-18T20:12:31   \n",
       "\n",
       "                from                                               text  \\\n",
       "0     Setup (Master)  Sawubona Jessie üòä. ;;We can see that you are e...   \n",
       "1          ThishaBot                                     Any questions?   \n",
       "2      Irfaan Moolla                                              Today   \n",
       "3  TZ Simphiwe Mfaba                                        Kulungile üí™   \n",
       "4          ThishaBot  Surprisingly, the patient seems satisfied with...   \n",
       "\n",
       "    from_2        type category  \\\n",
       "0    setup  noncontent    setup   \n",
       "1      bot  noncontent     conv   \n",
       "2  student  noncontent     conv   \n",
       "3    tutor  noncontent     conv   \n",
       "4      bot     content  non mcq   \n",
       "\n",
       "                                              text_2  \n",
       "0  setup Sawubona Jessie üòä. ;;We can see that you...  \n",
       "1                                 bot Any questions?  \n",
       "2                                      student Today  \n",
       "3                                  tutor Kulungile üí™  \n",
       "4  bot Surprisingly, the patient seems satisfied ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['text_2']\n",
    "y = train['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state =12, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> label encode and one-hot encode categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "y_train=le.fit_transform(y_train)\n",
    "y_test=le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483,) (121,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes=6\n",
    "# y_train = keras.utils.to_categorical(y_train,num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> use sklearn's vectorizer to format text data at word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483, 789)\n",
      "(121, 789)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_vec = TfidfVectorizer(analyzer='word',\n",
    "                         min_df=2,\n",
    "                         strip_accents='unicode',\n",
    "                         token_pattern=r'\\w{1,}',\n",
    "                         ngram_range=(2,3)\n",
    "                         )\n",
    "x_train_vec = tf_vec.fit_transform(x_train)\n",
    "x_test_vec = tf_vec.transform(x_test)\n",
    "print (x_train_vec.shape)\n",
    "print (x_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores- from kaggle:https://www.kaggle.com/ksjpswaroop/parameter-tuning-rf-randomized-search\n",
    "def report(results, n_top=5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import RandomizedSearchCV as RS\n",
    "from scipy import stats\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def create_model_2(dropout_rate=0.0, weight_constraint=0, hidden_layers=1, neurons=1, input_neurons=1, dropout_layers=1):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(input_neurons, activation='relu', input_shape=(789,)))\n",
    "    for i in np.arange(hidden_layers, dropout_layers):\n",
    "        model2.add(Dense(neurons, activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "        model2.add(Dropout(dropout_rate))\n",
    "    model2.add(Dense(6, activation='softmax'))\n",
    "    model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KerasClassifier(build_fn=create_model_2, verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'input_neurons': stats.randint(2,256),\n",
    "         'neurons': stats.randint(2, 64),\n",
    "         'hidden_layers': stats.randint(1, 5),\n",
    "          'dropout_layers': stats.randint(1,5),\n",
    "         'dropout_rate': stats.uniform(0.0, 0.9),\n",
    "         'weight_constraint': stats.uniform(1, 5)\n",
    "         }\n",
    "n_iter = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand2 = RS(estimator=model2, param_distributions=params, n_jobs=-1, cv=4, n_iter=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_search2 = rand2.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.609 (std: 0.034)\n",
      "Parameters: {'dropout_layers': 1, 'dropout_rate': 0.08782427604822979, 'hidden_layers': 4, 'input_neurons': 177, 'neurons': 6, 'weight_constraint': 2.786347683448474}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.596 (std: 0.008)\n",
      "Parameters: {'dropout_layers': 4, 'dropout_rate': 0.0320401140603887, 'hidden_layers': 4, 'input_neurons': 197, 'neurons': 21, 'weight_constraint': 5.131840432374133}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.592 (std: 0.045)\n",
      "Parameters: {'dropout_layers': 4, 'dropout_rate': 0.26203805833644134, 'hidden_layers': 4, 'input_neurons': 173, 'neurons': 42, 'weight_constraint': 4.372603740524596}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.592 (std: 0.022)\n",
      "Parameters: {'dropout_layers': 1, 'dropout_rate': 0.2900175512061454, 'hidden_layers': 4, 'input_neurons': 171, 'neurons': 36, 'weight_constraint': 5.613096815127511}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.582 (std: 0.008)\n",
      "Parameters: {'dropout_layers': 1, 'dropout_rate': 0.7702644378342802, 'hidden_layers': 4, 'input_neurons': 196, 'neurons': 2, 'weight_constraint': 4.495971827638097}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(rand_search2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_layers=1\n",
    "# input_neurons=28\n",
    "# neurons=47\n",
    "# weight_constraint=1\n",
    "# dropout_rate=0.3357\n",
    "\n",
    "# def create_model_3(dropout_rate=0.3357, weight_constraint=1, neurons=47, input_neurons=28,hidden_layers=1):\n",
    "#     model3 = Sequential()\n",
    "#     model3.add(Dense(input_neurons, activation='relu', input_shape=(685,)))\n",
    "#     for i in np.arange():\n",
    "#         model3.add(Dense(neurons, activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "#         model3.add(Dropout(dropout_rate))\n",
    "#     model3.add(Dense(6, activation='softmax'))\n",
    "#     model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = KerasClassifier(build_fn=create_model_3, verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'batch_size': stats.randint(1,256),\n",
    "        'epochs': stats.randint(1,256)}\n",
    "n_iter = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand3 = RS(estimator=model3, param_distributions=params, n_jobs=-1, cv=4, n_iter=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_search3 = rand3.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(rand_search3.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "batch_size= [4,8,16,32,64,128,256]\n",
    "epochs=[4,8,16,32,64,128]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_pred = grid.fit(x_train_vec, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(grid_pred.best_score_)\n",
    "print(grid_pred.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(x=x_train_vec, y=y_train, batch_size=?, epochs=?)\n",
    "#test_loss, test_acc = model.evaluate(x_test_vec, y_test)\n",
    "#test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_model_2(optimizer='Adam'):\n",
    "    inputs = layers.Input(shape=(2163,))\n",
    "    hidden_1 = layers.Dense(units=32, activation='relu')(inputs)\n",
    "    dropout1 = layers.Dropout(0.5)(hidden_1)\n",
    "    hidden_2 = layers.Dense(units=32, activation='relu')(hidden_1)\n",
    "    dropout_2 = layers.Dropout(0.5)(hidden_2)\n",
    "    hidden_3 = layers.Dense(units=32, activation='relu')(hidden_2)\n",
    "    dropout_3 = layers.Dropout(0.5)(hidden_3)\n",
    "    hidden_4 = layers.Dense(units=32, activation='relu')(hidden_3)\n",
    "    dropout_4 = layers.Dropout(0.5)(hidden_3)\n",
    "    hidden_5 = layers.Dense(units=32, activation='relu')(hidden_4)\n",
    "    dropout_5 = layers.Dropout(0.5)(hidden_4)\n",
    "    outputs = layers.Dense(6, activation='softmax')(hidden_5)\n",
    "\n",
    "    model2= models.Model(inputs=inputs, outputs=outputs)\n",
    "    #model.summary()\n",
    "    model2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model_2, verbose=0, batch_size=32, epochs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_pred = grid.fit(x_train_vec, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(grid_pred.best_score_)\n",
    "print(grid_pred.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
